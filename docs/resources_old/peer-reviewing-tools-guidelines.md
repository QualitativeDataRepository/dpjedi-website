---
title: Data-PASS Journal Editors Discussion Interface (JEDI) - Peer Reviewing Tools & Guidelines
layout: jedi
page_title: Resources
sidebar: true
join: false
post: false
---
## Peer Reviewing Tools & Guidelines {#peer-reviewing-tools-guidelines}

[EASE](https://ease.org.uk/) provides several guides for reviewers in their Peer Review Toolkit, including one on [how to write a review report](https://ease.org.uk/communities/peer-review-committee/peer-review-toolkit/how-to-write-a-review/) and a list of [peer review training options](https://ease.org.uk/communities/peer-review-committee/peer-review-toolkit/peer-review-training/).

One way editors can help reviewers is to make explicit the values and requirements of the journal so that reviewers can reflect these in their responses. For example, [*Language Development Research*](https://lps.library.cmu.edu/LDR/) makes it explicit in their [reviewer guidelines](https://lps.library.cmu.edu/LDR/site/reviewerguidelines/) that they wish to publish any research that meets their rigor criteria, without regard to the perceived novelty or importance of the findings.

The Society for Personality and Social Psychology created [guidelines for more inclusive reviewing practices](https://spsp.org/professional-development/publishing-resources/resources-for-inclusive-practices/guidelines-for-inclusive-reviewing-practices).

There are also tools being developed to guide peer reviewers in evaluating the manuscript, which journals can choose to implement. For example, [the INFORMS Journal on Data Science provides guidelines for reviewers](https://pubsonline.informs.org/page/ijds/reviewer-guidelines), and Elsevier makes available [a structured peer review question bank](https://www.elsevier.com/reviewers/how-to-review/structured-peer-review), from which journals may choose different questions to provide reviewers with as a way to guide their evaluation of each manuscript. In a similar spirit, [Schiavone et al. (2023)](https://psyarxiv.com/fc8v3/) have developed [an open-source tool for evaluating threats to the validity of empirical research (“Seaboat”)](https://www.seaboat.io/), which can generate reports to be shared alongside traditional peer reviews.

[Statcheck is also a popular tool for checking the consistency of reported statistics](https://michelenuijten.shinyapps.io/statcheck-web/), which can help journals, reviewers, and authors quickly and easily identify reporting errors that might otherwise go unnoticed.